"""
í˜‘ì—… í•„í„°ë§(Collaborative Filtering) ì¤‘ì—ì„œ ëª¨ë¸ë² ì´ìŠ¤ í–‰ë ¬ë¶„í•´(Matrix Factorization) ê³„ì—´
ALS ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ (user_id â†’ place_id)
ë°ì´í„°Â·í–‰ë ¬ í˜•íƒœ ìš”ì•½
train_user_items, test_user_items: CSR, shape = (n_users, n_items), float32.
train_implicit, test_implicit: ì´ì§„ CSR, ë™ì¼ shape.
ë§¤í•‘:
uid2idx: user_id â†’ [0..n_users)
pid2idx: place_id â†’ [0..n_items)
ì—­ë§¤í•‘ í¬í•¨.
í‰ê°€ ì§€í‘œ í•´ì„
precision@K: ìƒìœ„ K ì¤‘ ì •ë‹µ ë¹„ìœ¨.
map@K: í‰ê·  ì •ë°€ë„ì˜ ìƒìœ„ K ì ˆë‹¨ í‰ê· .
ndcg@K: ìˆœìœ„ ë¯¼ê° ì •ê·œí™” ëˆ„ì  ì´ë“.
auc@K(ìˆì„ ë•Œ): ìƒìœ„ K êµ¬ê°„ ë‚´ ë¶„ë¦¬ëŠ¥ ì§€í‘œ.
ì˜ˆì™¸Â·ì—£ì§€ ì¼€ì´ìŠ¤
CSVì— í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½ â†’ ValueError.
preprocess ì´ì „ì— build_mappings ë“± í˜¸ì¶œ â†’ RuntimeError.
split_data ì´í›„ íŠ¹ì • ìœ ì €ê°€ train/testì—ë§Œ ì¡´ì¬í•  ìˆ˜ ìˆìŒ. í–‰ë ¬ ì°¨ì›ì€ ì „ì²´ ë§¤í•‘ ê¸°ì¤€ì´ë¼ ì¼ê´€ì„± ìœ ì§€.
ì¶”ì²œ ì‹œ user_id ë¯¸ì¡´ì¬ â†’ ValueError.
ì‹œê°„Â·ê³µê°„ ë³µì¡ë„ ê°œê´„
ë§¤í•‘ ìƒì„±: O(U + I).
CSR ìƒì„±: O(nnz).
í•™ìŠµ: ë°˜ë³µë‹¹ ëŒ€ëµ O((U + I)Â·KÂ³)ì— ê°€ê¹Œìš´ ì„ í˜•ì‹œìŠ¤í…œ ë‹¤ìˆ˜ í•´ë²• + í¬ì†Œê³± ë¹„ìš©. ì‹¤ì œëŠ” êµ¬í˜„ ìµœì í™”ì™€ ìŠ¤ë ˆë“œ ë³‘ë ¬í™”ì— ì¢Œìš°.
ì¶”ì²œ ë‹¨ì¼ ìœ ì €: O(IÂ·K) ê·¼ì‚¬. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‚´ë¶€ ìµœì í™” ì ìš©.
"""

import os
os.environ['OPENBLAS_NUM_THREADS'] = '1'

import numpy as np
import pandas as pd
from scipy.sparse import csr_matrix
from sklearn.model_selection import train_test_split
from implicit.als import AlternatingLeastSquares
from implicit.nearest_neighbours import bm25_weight
import pickle

# í‰ê°€ í•¨ìˆ˜ import (ë²„ì „ë³„ AUC ì²˜ë¦¬)
try:
    from implicit.evaluation import (
        precision_at_k,
        mean_average_precision_at_k,
        ndcg_at_k,
        AUC_at_k,
    )
    HAS_AUC = True
except ImportError:
    from implicit.evaluation import (
        precision_at_k,
        mean_average_precision_at_k,
        ndcg_at_k,
    )
    HAS_AUC = False


class ALSRecommender:
    """ALS ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ (user_id â†’ place_id)
    - ì…ë ¥ ë°ì´í„° ì»¬ëŸ¼ ìš”êµ¬ì‚¬í•­: 'user_id', 'place_id', 'rating'
    """

    def __init__(self,
                 factors: int = 64,
                 regularization: float = 0.08,
                 iterations: int = 20,
                 use_gpu: bool = False):
        self.factors = factors
        self.regularization = regularization
        self.iterations = iterations
        self.use_gpu = use_gpu

        self.df: pd.DataFrame | None = None
        self.train_df: pd.DataFrame | None = None
        self.test_df: pd.DataFrame | None = None

        self.uid2idx: dict[str, int] | None = None
        self.pid2idx: dict[str | int, int] | None = None
        self.idx2uid: dict[int, str] | None = None
        self.idx2pid: dict[int, str | int] | None = None

        self.train_user_items: csr_matrix | None = None
        self.test_user_items: csr_matrix | None = None
        self.train_implicit: csr_matrix | None = None
        self.test_implicit: csr_matrix | None = None

        self.model: AlternatingLeastSquares | None = None

    # ---------- ë°ì´í„° ë¡œë“œ/ì „ì²˜ë¦¬ ----------
    def load_data(self, csv_path: str = "good_data.csv") -> None:
        """
        ì…ë ¥: CSV ê²½ë¡œ. í•„ìš”í•œ ì»¬ëŸ¼: user_id, place_id, rating.
        ì²˜ë¦¬: CSV ë¡œë“œ â†’ í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ â†’ ì„œë¸Œì…‹Â·ê²°ì¸¡ ì œê±°.
        ìƒíƒœ ë³€í™”: self.df ì„¤ì •.
        ì˜ˆì™¸: ëˆ„ë½ ì»¬ëŸ¼ ì‹œ ValueError.
        ì¶œë ¥: ì—†ìŒ.
        """
        self.df = pd.read_csv(csv_path)
        required = {"user_id", "place_id", "rating"}
        missing = required - set(self.df.columns)
        if missing:
            raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {sorted(missing)}")
        self.df = self.df[["user_id", "place_id", "rating"]].dropna()
        print(f"âœ“ ë°ì´í„° ë¡œë“œ: {len(self.df)} rows")

    def preprocess(self) -> None:
        """
        ì „ì œ: self.df ì¡´ì¬.
        ì²˜ë¦¬: ì¸ë±ìŠ¤ ë¦¬ì…‹. ì¶”ê°€ ì „ì²˜ë¦¬ ì—†ìŒ.
        ìƒíƒœ ë³€í™”: self.df ë®ì–´ì”€.
        ì˜ˆì™¸: ë¯¸í˜¸ì¶œ ì‹œ RuntimeError.
        ì¶œë ¥: ì—†ìŒ.
        """
        if self.df is None:
            raise RuntimeError("ë¨¼ì € load_data()ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")
        # user_id, place_id, ratingë§Œ ì‚¬ìš©
        self.df = self.df.reset_index(drop=True)
        print(f"âœ“ ì „ì²˜ë¦¬ ì™„ë£Œ: í–‰ìˆ˜={len(self.df)}")

    def build_mappings(self) -> None:
        """
        ì „ì œ: self.df ì¡´ì¬.
        ì²˜ë¦¬: ë§¤í•‘ ìƒì„±.
            - uid2idx: ê³ ìœ  user_id ì •ë ¬ í›„ 0..U-1 ë§¤í•‘.
            - pid2idx: ê³ ìœ  place_id ì •ë ¬ í›„ 0..I-1 ë§¤í•‘.
            - idx2uid: uid2idx ì—­ë§¤í•‘.
            - idx2pid: pid2idx ì—­ë§¤í•‘.
        ìƒíƒœ ë³€í™”: self.uid2idx, self.pid2idx, self.idx2uid, self.idx2pid ì„¤ì •.
        ì˜ˆì™¸: ë¯¸í˜¸ì¶œ ì‹œ RuntimeError.
        ì¶œë ¥: ì—†ìŒ.
        """
        if self.df is None:
            raise RuntimeError("ë¨¼ì € load_data()/preprocess()ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")
        self.uid2idx = {u: i for i, u in enumerate(sorted(self.df["user_id"].unique()))}
        self.pid2idx = {p: i for i, p in enumerate(sorted(self.df["place_id"].unique()))}
        self.idx2uid = {i: u for u, i in self.uid2idx.items()}
        self.idx2pid = {i: p for p, i in self.pid2idx.items()}
        print(f"âœ“ ë§¤í•‘ ìƒì„±: users={len(self.uid2idx)}, items={len(self.pid2idx)}")

    def split_data(self, test_size: float = 0.2, random_state: int = 42) -> None:
        """
        ì „ì œ: self.df ì¡´ì¬.
        ì²˜ë¦¬: rating ê¸°ì¤€ ì¸µí™” ë¶„í• . í•™ìŠµ/í‰ê°€ ë¶„ë¦¬
        ìƒíƒœ ë³€í™”: self.train_df, self.test_df ì„¤ì •.
        ì˜ˆì™¸: ë¯¸í˜¸ì¶œ ì‹œ RuntimeError.
        ì¶œë ¥: ì—†ìŒ.
        """
        if self.df is None:
            raise RuntimeError("ë¨¼ì € load_data()/preprocess()ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")
        self.train_df, self.test_df = train_test_split(
            self.df, test_size=test_size, stratify=self.df["rating"], random_state=random_state
        )
        print(f"âœ“ ë°ì´í„° ë¶„í• : train={len(self.train_df)}, test={len(self.test_df)}")

    # ---------- í–‰ë ¬ ìœ í‹¸ ----------
    def _ensure_csr32(self, m: csr_matrix) -> csr_matrix:
        """
        ì…ë ¥: ì„ì˜ CSR
        ì²˜ë¦¬: CSRë¡œ ê°•ì œ, float32, ì¸ë±ìŠ¤ ì •ë ¬.
        ì¶œë ¥: csr_matrix. (ì •ê·œí™”ëœ CSR)
        ë³µì¡ë„: O(nnz)
        """
        m = m.tocsr().astype(np.float32)
        m.sort_indices()
        return m

    def _build_user_item(self, source_df: pd.DataFrame, rating_col: str = "rating") -> csr_matrix:
        """
        ì „ì œ: source_df ì¡´ì¬, uid2idx, pid2idx ì„¤ì •.
        ì²˜ë¦¬: rows=user_idâ†’uid2idx, cols=place_idâ†’pid2idx, data=rating
        ìƒíƒœ ë³€í™”: x
        ì˜ˆì™¸: ë¯¸í˜¸ì¶œ ì‹œ RuntimeError.
        ì¶œë ¥: csr_matrix. (n_users, n_items)ì˜ CSR
        ë³µì¡ë„: O(nnz)
        """
        if self.uid2idx is None or self.pid2idx is None:
            raise RuntimeError("ë¨¼ì € build_mappings()ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")
        rows = source_df["user_id"].map(self.uid2idx).astype(np.int32).to_numpy()
        cols = source_df["place_id"].map(self.pid2idx).astype(np.int32).to_numpy()
        data = source_df[rating_col].astype(np.float32).to_numpy()
        m = csr_matrix(
            (data, (rows, cols)),
            shape=(len(self.uid2idx), len(self.pid2idx)),
            dtype=np.float32,
        )
        m.sort_indices()
        return m

    def _binarize_geq3(self, m: csr_matrix) -> csr_matrix:
        """
        ì…ë ¥: CSR
        ì²˜ë¦¬: data>=3ë¥¼ 1.0, ê·¸ ì™¸ 0ìœ¼ë¡œ ì´ì§„í™”. 0 ì œê±°. ì¸ë±ìŠ¤ ì •ë ¬
        ì¶œë ¥: ì´ì§„ CSR
        ë¹„ê³ : ì„ê³„ê°’ 3 ê³ ì •
        """
        m = m.copy().tocsr()
        mask = m.data >= 3.0
        m.data[:] = mask.astype(np.float32)
        m.eliminate_zeros()
        m.sort_indices()
        return m

    def build_matrices(self) -> None:
        """
        ì „ì œ: train_df, test_df ì¡´ì¬.
        ì²˜ë¦¬:
            - í•™ìŠµ/í…ŒìŠ¤íŠ¸ì—ì„œ ìœ ì €â€“ì•„ì´í…œ í–‰ë ¬ ìƒì„±
            - ê°ê° ì´ì§„í™”í•˜ì—¬ train_implicit, test_implicit ìƒì„±
        ìƒíƒœ ë³€í™”: ë„¤ ê°œ CSR ì†ì„± ì„¤ì •.
        ì˜ˆì™¸: ë¯¸í˜¸ì¶œ ì‹œ RuntimeError.
        """
        if self.train_df is None or self.test_df is None:
            raise RuntimeError("ë¨¼ì € split_data()ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")
        self.train_user_items = self._ensure_csr32(self._build_user_item(self.train_df))
        self.test_user_items = self._ensure_csr32(self._build_user_item(self.test_df))
        self.train_implicit = self._binarize_geq3(self.train_user_items)
        self.test_implicit = self._binarize_geq3(self.test_user_items)
        print("âœ“ í–‰ë ¬ ìƒì„± ì™„ë£Œ (train/test implicit)")

    # ---------- í•™ìŠµ/í‰ê°€ ----------
    def train(self, use_bm25: bool = False) -> None:
        """
        ì „ì œ: train_implicit ì¡´ì¬.
        ì²˜ë¦¬:
            - train_for_fit = train_implicit ë˜ëŠ” bm25_weight(train_implicit) í›„ float32.
            - AlternatingLeastSquares ì¸ìŠ¤í„´ìŠ¤ ìƒì„±.
            - model.fit(train_for_fit).
        ìƒíƒœ ë³€í™”: self.model í•™ìŠµ ì™„ë£Œ.
        ì˜ˆì™¸: ë¯¸í˜¸ì¶œ ì‹œ RuntimeError.
        ì…ë ¥ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì˜í–¥:
            - factors: ì ì¬ ì°¨ì›
            - regularization: L2 ê·œì œ
            - iterations: ALS ë°˜ë³µ ìˆ˜
            - use_gpu: GPU ì‚¬ìš© ì—¬ë¶€
        """
        if self.train_implicit is None:
            raise RuntimeError("ë¨¼ì € build_matrices()ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")
        train_for_fit = self._ensure_csr32(bm25_weight(self.train_implicit)) if use_bm25 else self.train_implicit
        self.model = AlternatingLeastSquares(
            factors=self.factors,
            regularization=self.regularization,
            iterations=self.iterations,
            use_gpu=self.use_gpu,
        )
        # implicitëŠ” recommend í˜¸ì¶œ ì‹œ user_itemsë¥¼ ë„˜ê¸°ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ê·¸ëŒ€ë¡œ fit ê°€ëŠ¥
        self.model.fit(train_for_fit)
        print("âœ“ ALS í•™ìŠµ ì™„ë£Œ")

    def evaluate(self, K: int = 10) -> dict:
        """
        ì „ì œ: model, train_implicit, test_implicit ì¡´ì¬.
        ì²˜ë¦¬: precision@K, map@K, ndcg@K, ì˜µì…˜ìœ¼ë¡œ auc@K.
        ì¶œë ¥: {metric_name: float} ë”•ì…”ë„ˆë¦¬.
        ìƒíƒœ ë³€í™”: ì—†ìŒ.
        ì˜ˆì™¸: ë‚´ë¶€ ì§€í‘œ ê³„ì‚° ì¤‘ ì˜ˆì™¸ë¥¼ ì¡ì•„ ë©”ì‹œì§€ ì¶œë ¥ í›„ í•´ë‹¹ ê°’ ë¯¸ê¸°ë¡ ë˜ëŠ” í‚¤ ë‹¤ë¦„(ì½”ë“œ ê·¸ëŒ€ë¡œ).
        """
        if self.model is None or self.train_implicit is None or self.test_implicit is None:
            raise RuntimeError("ë¨¼ì € train()ì„ ì™„ë£Œí•˜ì„¸ìš”.")
        results = {}
        try:
            results[f"precision@{K}"] = float(
                precision_at_k(self.model, self.train_implicit, self.test_implicit, K=int(K), show_progress=False)
            )
        except Exception as e:
            print(f"Error In precision_at_k: {e}")
        try:
            results[f"map@{K}"] = float(
                mean_average_precision_at_k(self.model, self.train_implicit, self.test_implicit, K=int(K), show_progress=False)
            )
        except Exception as e:
            print(f"Error In mean_average_precision_at_k: {e}")
        try:
            results[f"ndcg@{K}"] = float(
                ndcg_at_k(self.model, self.train_implicit, self.test_implicit, K=int(K), show_progress=False)
            )
        except Exception as e:
            print(f"Error In ndcg_at_k: {e}")
        if HAS_AUC:
            try:
                results[f"auc@{K}"] = float(AUC_at_k(self.model, self.train_implicit, self.test_implicit, K=int(K), show_progress=False))
            except TypeError:
                results["auc"] = float(AUC_at_k(self.model, self.train_implicit, self.test_implicit))
            except Exception as e:
                print(f"Error In AUC_at_k: {e}")
        print("ğŸ“Š í‰ê°€:", results)
        return results

    # ---------- ì¶”ì²œ ----------
    def recommend(self,
                  user_id,
                  N: int = 10,
                  filter_already_liked_items: bool = False) -> list[tuple[str | int, float]]:
        """
        ì „ì œ: model, train_implicit, uid2idx, idx2pid ì¡´ì¬.
        ì²˜ë¦¬:
           - user_idë¥¼ ë‚´ë¶€ ì¸ë±ìŠ¤ë¡œ ë³€í™˜.
           - model.recommend(userid=uid, user_items=train_implicit, N, filter_already_liked_items=...).
           - ì•„ì´í…œ ì¸ë±ìŠ¤ë¥¼ place_idë¡œ ì—­ë§¤í•‘.
        ì¶œë ¥: [(place_id, score), ...] ê¸¸ì´ N ë¦¬ìŠ¤íŠ¸.
        ìƒíƒœ ë³€í™”: ì—†ìŒ.
        ì˜ˆì™¸: ë¯¸ë“±ë¡ user_idëŠ” ValueError.
        ì ìˆ˜ ì˜ë¯¸: ì‚¬ìš©ìÂ·ì•„ì´í…œ ì ì¬ë²¡í„° ë‚´ì  ê¸°ë°˜ ì¶”ì²œ ì ìˆ˜.
        """
        if self.model is None or self.train_implicit is None:
            raise RuntimeError("ë¨¼ì € train()ì„ ì™„ë£Œí•˜ì„¸ìš”.")
        if self.uid2idx is None or self.idx2pid is None:
            raise RuntimeError("ë¨¼ì € build_mappings()ì„ ì™„ë£Œí•˜ì„¸ìš”.")
        if user_id not in self.uid2idx:
            raise ValueError(f"ë“±ë¡ë˜ì§€ ì•Šì€ user_id: {user_id}")
        uid = self.uid2idx[user_id]
        rec_idx, rec_scores = self.model.recommend(
            userid=uid,
            user_items=self.train_implicit,
            N=int(N),
            filter_already_liked_items=filter_already_liked_items,
        )
        return [(self.idx2pid[int(i)], float(s)) for i, s in zip(rec_idx, rec_scores)]

    def recommend_df(self,
                     user_id,
                     N: int = 10,
                     filter_already_liked_items: bool = False) -> pd.DataFrame:
        """
        ì „ì œ: recommend ê°€ëŠ¥.
        ì²˜ë¦¬: recommend í˜¸ì¶œ â†’ DataFrame ë³€í™˜ â†’ ì†Œìˆ˜ì  4ìë¦¬ ë°˜ì˜¬ë¦¼
        ì¶œë ¥: ì»¬ëŸ¼ ["place_id","score"]ì˜ pd.DataFrame
        """
        recs = self.recommend(user_id=user_id, N=N, filter_already_liked_items=filter_already_liked_items)
        return pd.DataFrame(recs, columns=["place_id", "score"]).assign(score=lambda d: d["score"].round(4))

    # ---------- ì €ì¥/ë¡œë“œ ----------
    def save_model(self, model_path: str = "als_model.pkl") -> bool:
        """
        ì „ì œ: model, uid2idx, pid2idx ì¡´ì¬.
        ì²˜ë¦¬:
            - íŒŒë¼ë¯¸í„°, user_factors, item_factors, ë§¤í•‘ 4ì¢…ì„ dictë¡œ í”¼í´ ì €ì¥
        ì¶œë ¥: ì„±ê³µ True, ì‹¤íŒ¨ False.
        ì˜ˆì™¸: ì „ì œ ë¶ˆë§Œì¡± ì‹œ RuntimeError. ì €ì¥ ì¤‘ ì˜ˆì™¸ëŠ” ì¡ì•„ ë©”ì‹œì§€ ì¶œë ¥ í›„ False.
        """
        if self.model is None or self.uid2idx is None or self.pid2idx is None:
            raise RuntimeError("ëª¨ë¸/ë§¤í•‘ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € train() ë° build_mappings()ë¥¼ ì™„ë£Œí•˜ì„¸ìš”.")
        try:
            data = {
                "params": {
                    "factors": self.factors,
                    "regularization": self.regularization,
                    "iterations": self.iterations,
                    "use_gpu": self.use_gpu,
                },
                # implicit ALSëŠ” ì „ì²´ ê°ì²´ í”¼í´ë³´ë‹¤ factor í–‰ë ¬ ì €ì¥ì´ ì•ˆì „
                "user_factors": getattr(self.model, "user_factors", None),
                "item_factors": getattr(self.model, "item_factors", None),
                "uid2idx": self.uid2idx,
                "pid2idx": self.pid2idx,
                "idx2uid": self.idx2uid,
                "idx2pid": self.idx2pid,
            }
            with open(model_path, "wb") as f:
                pickle.dump(data, f)
            size_mb = os.path.getsize(model_path) / (1024 * 1024)
            print(f"âœ“ ALS ëª¨ë¸ ì €ì¥: {model_path} ({size_mb:.2f} MB)")
            return True
        except Exception as e:
            print(f"âœ— ALS ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def load_model(self, model_path: str = "als_model.pkl") -> bool:
        """
        ì…ë ¥: í”¼í´ ê²½ë¡œ.
        ì²˜ë¦¬:
            - íŒŒì¼ í™•ì¸ í›„ ë¡œë“œ.
            - ì €ì¥ëœ íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ì¬ìƒì„±.
            - user_factors, item_factorsê°€ ìˆìœ¼ë©´ ì£¼ì….
            - ë§¤í•‘ 4ì¢… ë³µêµ¬.
        ì¶œë ¥: ì„±ê³µ True, ì‹¤íŒ¨ False.
        ë¶€ê°€ ì¶œë ¥: íŒŒì¼ í¬ê¸°, ìœ ì €Â·ì•„ì´í…œ ìˆ˜ í‘œì‹œ.
        ì˜ˆì™¸: ë¡œë“œ ì¤‘ ì˜ˆì™¸ëŠ” ì¡ì•„ ë©”ì‹œì§€ ì¶œë ¥ í›„ False.
        """
        try:
            if not os.path.exists(model_path):
                print(f"âœ— ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
                return False
            with open(model_path, "rb") as f:
                data = pickle.load(f)

            params = data.get("params", {})
            self.factors = int(params.get("factors", self.factors))
            self.regularization = float(params.get("regularization", self.regularization))
            self.iterations = int(params.get("iterations", self.iterations))
            self.use_gpu = bool(params.get("use_gpu", self.use_gpu))

            # ë§¤í•‘ ë³µêµ¬
            self.uid2idx = data.get("uid2idx")
            self.pid2idx = data.get("pid2idx")
            self.idx2uid = data.get("idx2uid")
            self.idx2pid = data.get("idx2pid")

            # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í›„ factor ì£¼ì…
            self.model = AlternatingLeastSquares(
                factors=self.factors,
                regularization=self.regularization,
                iterations=self.iterations,
                use_gpu=self.use_gpu,
            )
            uf = data.get("user_factors")
            itf = data.get("item_factors")
            if uf is None or itf is None:
                print("âš ï¸ ì €ì¥ëœ factorê°€ ì—†ì–´ ì¬í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤.")
            else:
                self.model.user_factors = uf
                self.model.item_factors = itf

            # ì¶”ì²œì´ ê³§ì¥ ê°€ëŠ¥í•˜ë„ë¡ ë¹ˆ ì‚¬ìš©ì-ì•„ì´í…œ í–‰ë ¬ì„ ì´ˆê¸°í™”
            # (í•„í„°ë§/ê°€ì¤‘ ëª©ì ì˜ í•™ìŠµ í–‰ë ¬ì´ ì—†ì„ ê²½ìš°ì—ë„ API ìš”êµ¬ì‚¬í•­ ì¶©ì¡±)
            from scipy.sparse import csr_matrix as _csr
            if self.uid2idx is not None and self.pid2idx is not None:
                self.train_implicit = _csr((len(self.uid2idx), len(self.pid2idx)), dtype=np.float32)

            size_mb = os.path.getsize(model_path) / (1024 * 1024)
            print(f"âœ“ ALS ëª¨ë¸ ë¡œë“œ: {model_path} ({size_mb:.2f} MB)")
            print(f"  - users: {len(self.uid2idx) if self.uid2idx else 0}, items: {len(self.pid2idx) if self.pid2idx else 0}")
            return True
        except Exception as e:
            print(f"âœ— ALS ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False


def main():
    recommender = ALSRecommender()
    # 1) ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ ì‹œë„
    loaded = recommender.load_model("als_model.pkl")

    # 2) ëª¨ë¸/íŒ©í„°ê°€ ì—†ìœ¼ë©´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    needs_training = (
        not loaded or
        recommender.model is None or
        getattr(recommender.model, "user_factors", None) is None or
        getattr(recommender.model, "item_factors", None) is None or
        recommender.uid2idx is None or recommender.pid2idx is None
    )

    if needs_training:
        print("ğŸ”„ ì €ì¥ëœ ëª¨ë¸ì´ ì—†ê±°ë‚˜ ë¶ˆì™„ì „í•©ë‹ˆë‹¤. í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        recommender.load_data("good_data.csv")
        recommender.preprocess()
        recommender.build_mappings()
        recommender.split_data(test_size=0.2)
        recommender.build_matrices()
        recommender.train(use_bm25=False)
        recommender.evaluate(K=10)
        recommender.save_model("als_model.pkl")

    # 3) ì˜ˆì‹œ ì¶”ì²œ: ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ” ì„ì˜ì˜ user_id ì„ íƒ
    try:
        example_user = next(iter(recommender.uid2idx.keys())) if recommender.uid2idx else None
        if example_user is None:
            print("ì¶”ì²œ ì—ëŸ¬: ì‚¬ìš©ì ì—†ìŒ")
        else:
            print(f"ğŸ§ª ìƒ˜í”Œ ì‚¬ìš©ì: {example_user}")
            df_rec = recommender.recommend_df(example_user, N=10)
            print(df_rec.head())
    except Exception as e:
        print(f"ì¶”ì²œ ì—ëŸ¬: {e}")

    # ë””ë²„ê·¸: í˜•ìƒ/íƒ€ì… í™•ì¸ì´ í•„ìš”í•  ë•Œë§Œ ì‚¬ìš©
    # print("train_implicit dtype:", recommender.train_implicit.dtype,
    #       recommender.train_implicit.data.dtype, recommender.train_implicit.indices.dtype, recommender.train_implicit.indptr.dtype)

    return recommender


if __name__ == "__main__":
    main()