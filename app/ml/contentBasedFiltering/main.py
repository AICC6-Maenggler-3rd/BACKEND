import pandas as pd
import numpy as np
import ast
import pickle
import os
from scipy.sparse import hstack  # Sparse matrix ê²°í•©ìš©
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler
from sklearn.metrics import precision_score, recall_score, f1_score, ndcg_score
import warnings
warnings.filterwarnings('ignore')

class TravelRecommendationSystem:
    """ì—¬í–‰ì§€ ì¶”ì²œ ì‹œìŠ¤í…œ í´ë˜ìŠ¤"""

    def __init__(self):
        self.places_df = None
        self.similarity_matrix = None
        self.tfidf_vectorizer = TfidfVectorizer()
        self.mlb_category = MultiLabelBinarizer()
        self.mlb_suitable = MultiLabelBinarizer()
        self.feature_matrix = None
        # Sparse matrixìš© ë³„ë„ ì €ì¥ (ë©”ëª¨ë¦¬ ìµœì í™”)
        self.tfidf_matrix = None
        self.category_matrix = None
        self.suitable_matrix = None
        self.scaler = StandardScaler()
        self.address_similarity_matrix = None  # ì§€ì—­ëª… ìœ ì‚¬ë„ í–‰ë ¬
        self.address_vectorizer = TfidfVectorizer()  # ì§€ì—­ëª… ì„ë² ë”©ìš©

    def load_data(self, csv_path='final_data.csv'):
        """
        CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
        ì˜ˆìƒ ì»¬ëŸ¼:
        - place_id: ì¥ì†Œ ID
        - name: ì¥ì†Œëª…
        - address: ì£¼ì†Œëª…
        - category: ì¹´í…Œê³ ë¦¬
        - suitable: ì í•©í•œ êµ¬ì„±ì› (ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ì½¤ë§ˆ êµ¬ë¶„)
        - address_la: ìœ„ë„
        - address_lo: ê²½ë„
        - type: ì¥ì†Œ ìœ í˜•
        - count: ì¥ì†Œ ê°œìˆ˜
        - website: ì›¹ì‚¬ì´íŠ¸
        - image_url: ì´ë¯¸ì§€ URL
        - insta_nickname: ì¸ìŠ¤íƒ€ê·¸ë¨ ë‹‰ë„¤ì„
        - open_hour: ì˜¤í”ˆ ì‹œê°„
        - close_hour: í´ë¡œì¦ˆ ì‹œê°„
        - description: ì„¤ëª…
        """
        try:
            self.places_df = pd.read_csv(csv_path)
            print(f"âœ“ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.places_df)}ê°œ ì¥ì†Œ")
            return True
        except Exception as e:
            print(f"âœ— ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def preprocess_data(self):
        """ë°ì´í„° ì „ì²˜ë¦¬"""

        print("\n=== ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘ ===")

        # ë¬¸ìì—´ í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‹¤ì œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
        def parse_string_list(value):
            """ë¬¸ìì—´ í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ íŒŒì‹±"""
            if pd.isna(value):
                return []
            if isinstance(value, str):
                try:
                    # ast.literal_evalì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ìì—´ í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‹¤ì œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    parsed = ast.literal_eval(value)
                    if isinstance(parsed, list):
                        return parsed
                    else:
                        return [parsed]
                except (ValueError, SyntaxError):
                    # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì½¤ë§ˆë¡œ ë¶„ë¦¬
                    return [x.strip() for x in value.split(',')]
            if isinstance(value, list):
                return value
            return []

        # í…Œë§ˆì™€ êµ¬ì„±ì›ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        if 'category' in self.places_df.columns:
            self.places_df['category_list'] = self.places_df['category'].apply(parse_string_list)

        if 'suitable' in self.places_df.columns:
            self.places_df['suitable_list'] = self.places_df['suitable'].apply(parse_string_list)
        
        # ì„¤ëª… ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ìƒì„±
        if 'description' not in self.places_df.columns:
            # categorys ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ category ì‚¬ìš©
            if 'categorys' in self.places_df.columns:
                self.places_df['description'] = (
                    self.places_df['name'] + ' ' +
                    self.places_df['category'].astype(str) + ' ' +
                    self.places_df['categorys'].astype(str)
                )
            else:
                self.places_df['description'] = (
                    self.places_df['name'] + ' ' +
                    self.places_df['category'].astype(str)
                )

        print(f"âœ“ ì „ì²˜ë¦¬ ì™„ë£Œ")

    def build_features(self):
        """íŠ¹ì§• í–‰ë ¬ êµ¬ì„±"""

        print("\n=== íŠ¹ì§• í–‰ë ¬ êµ¬ì„± ===")

        #  1. TF-IDF ë²¡í„° (í…ìŠ¤íŠ¸ ì„¤ëª…)
        self.tfidf_matrix = self.tfidf_vectorizer.fit_transform(
            self.places_df['description']
        )
        print(f"âœ“ TF-IDF í–‰ë ¬: {self.tfidf_matrix.shape} (sparse)")

        # 2. ì¹´í…Œê³ ë¦¬ ì›-í•« ì¸ì½”ë”©
        self.category_matrix = self.mlb_category.fit_transform(
            self.places_df['category_list']
        )
        print(f"âœ“ ì¹´í…Œê³ ë¦¬ í–‰ë ¬: {self.category_matrix.shape}")
        print(f"  ì¹´í…Œê³ ë¦¬ ì¢…ë¥˜: {self.mlb_category.classes_.tolist()}")

        # 3. êµ¬ì„±ì› ì›-í•« ì¸ì½”ë”©
        self.suitable_matrix = self.mlb_suitable.fit_transform(
            self.places_df['suitable_list']
        )
        print(f"âœ“ êµ¬ì„±ì› í–‰ë ¬: {self.suitable_matrix.shape}")
        print(f"  êµ¬ì„±ì› ì¢…ë¥˜: {self.mlb_suitable.classes_.tolist()}")

        # 4. ì§€ì—­ëª… ì„ë² ë”© ë° ìœ ì‚¬ë„ í–‰ë ¬ ìƒì„±
        address_matrix = self.address_vectorizer.fit_transform(
            self.places_df['address']
        )
        self.address_similarity_matrix = cosine_similarity(address_matrix)
        print(f"âœ“ ì§€ì—­ëª… ì„ë² ë”© ì™„ë£Œ: {address_matrix.shape}")
        print(f"âœ“ ì§€ì—­ëª… ìœ ì‚¬ë„ í–‰ë ¬ ìƒì„±: {self.address_similarity_matrix.shape}")

        # 5. ëª¨ë“  íŠ¹ì§• ê²°í•© (sparse matrixë¡œ ìœ ì§€)
        self.feature_matrix = hstack([
            self.tfidf_matrix,
            self.category_matrix * 2,  # ì¹´í…Œê³ ë¦¬ ê°€ì¤‘ì¹˜ ì¦ê°€
            self.suitable_matrix * 2,  # êµ¬ì„±ì› ê°€ì¤‘ì¹˜ ì¦ê°€
        ])

        print(f"âœ“ ìµœì¢… íŠ¹ì§• í–‰ë ¬: {self.feature_matrix.shape} (sparse)")

    def train_model(self):
        """
        ëª¨ë¸ í›ˆë ¨ (ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°)

        Content-Based Filtering ì‚¬ìš©:
        - ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¥ì†Œ ê°„ ìœ ì‚¬ë„ ê³„ì‚°
        - ì§€ì—­, ì¹´í…Œê³ ë¦¬, êµ¬ì„±ì›, ì¹´í…Œê³ ë¦¬ ë“±ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤
        """

        print("\n=== ëª¨ë¸ í›ˆë ¨ ì‹œì‘ ===")

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        self.similarity_matrix = cosine_similarity(self.feature_matrix)

        print(f"âœ“ ìœ ì‚¬ë„ í–‰ë ¬ ìƒì„± ì™„ë£Œ: {self.similarity_matrix.shape}")
        print(f"âœ“ í‰ê·  ìœ ì‚¬ë„: {self.similarity_matrix.mean():.4f}")
        print(f"âœ“ ìµœëŒ€ ìœ ì‚¬ë„: {self.similarity_matrix.max():.4f}")
        print(f"âœ“ ìµœì†Œ ìœ ì‚¬ë„: {self.similarity_matrix.min():.4f}")

    def evaluate_model(self, k=10, max_km=15.0, min_cat_overlap=1, min_suit_overlap=1):
        """
        í‰ê°€ ê¸°ì¤€(ê¶Œì¥):
        - ê±°ë¦¬: max_km km ì´ë‚´
        - ì¹´í…Œê³ ë¦¬ ê²¹ì¹¨: ìµœì†Œ min_cat_overlap ê°œ
        - êµ¬ì„±ì› ê²¹ì¹¨: ìµœì†Œ min_suit_overlap ê°œ
        """
        print("\n=== ëª¨ë¸ í‰ê°€ ===")
        print(f"ğŸ“ ê·¼ì ‘ ê¸°ì¤€: {max_km}km, ì¹´í…Œê³ ë¦¬â‰¥{min_cat_overlap}, êµ¬ì„±ì›â‰¥{min_suit_overlap}, Top-{k}")

        # ë²¡í„°í™” ì¤€ë¹„
        lat = np.radians(self.places_df['address_la'].values)
        lon = np.radians(self.places_df['address_lo'].values)
        cat_lists = self.places_df['category_list'].tolist()
        suit_lists = self.places_df['suitable_list'].tolist()

        precisions, recalls, ndcgs = [], [], []

        N = len(self.places_df)
        for idx in range(N):
            # --- 1) Ground truth êµ¬ì¶• ---
            # ê±°ë¦¬ ë²¡í„° (idx ê¸°ì¤€)
            dlat = lat - lat[idx]
            dlon = lon - lon[idx]
            a = np.sin(dlat/2)**2 + np.cos(lat[idx]) * np.cos(lat) * np.sin(dlon/2)**2
            dist_km = 2 * 6371 * np.arcsin(np.sqrt(a))

            # ì¹´í…Œê³ ë¦¬/êµ¬ì„±ì› ê²¹ì¹¨
            cats_i = set(cat_lists[idx])
            suits_i = set(suit_lists[idx])

            cat_overlap = np.array([len(cats_i & set(cat_lists[j])) for j in range(N)])
            suit_overlap = np.array([len(suits_i & set(suit_lists[j])) for j in range(N)])

            mask_gt = (
                (dist_km <= max_km) &
                (cat_overlap >= min_cat_overlap) &
                (suit_overlap >= min_suit_overlap)
            )
            mask_gt[idx] = False  # ìê¸° ìì‹  ì œì™¸
            relevant_idx = np.where(mask_gt)[0].tolist()

            if not relevant_idx:
                continue  # ì •ë‹µì´ ì—†ëŠ” ìƒ˜í”Œì€ ìŠ¤í‚µ

            # --- 2) ì˜ˆì¸¡ Top-K ---
            sims = self.similarity_matrix[idx].copy()
            sims[idx] = -1
            topk = sims.argsort()[-k:][::-1]

            # --- 3) Metrics ---
            rel_in_topk = len(set(topk) & set(relevant_idx))
            precision = rel_in_topk / k
            recall = rel_in_topk / len(relevant_idx)

            # NDCG@k (ì´ì§„ relevance)
            true_rel = np.zeros(N, dtype=int)
            true_rel[relevant_idx] = 1
            try:
                ndcg = ndcg_score([true_rel], [sims], k=k)
            except Exception:
                ndcg = 0.0

            precisions.append(precision)
            recalls.append(recall)
            ndcgs.append(ndcg)

        if not precisions:
            print("í‰ê°€ ê°€ëŠ¥í•œ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ì¤€ì„ ì™„í™”í•˜ì„¸ìš”.")
            return {'precision': 0, 'recall': 0, 'f1_score': 0, 'ndcg': 0}

        P, R, N = np.mean(precisions), np.mean(recalls), np.mean(ndcgs)
        F1 = 2*P*R/(P+R) if (P+R) > 0 else 0

        print(f"\nğŸ“Š í‰ê°€ ê²°ê³¼ (Top-{k}):")
        print(f"  - Precision@{k}: {P:.4f} (Â±{np.std(precisions):.4f})")
        print(f"  - Recall@{k}: {R:.4f} (Â±{np.std(recalls):.4f})")
        print(f"  - NDCG@{k}: {N:.4f} (Â±{np.std(ndcgs):.4f})")
        print(f"  - F1-Score: {F1:.4f}")
        print(f"\nğŸ“ˆ ì¶”ê°€ ë¶„ì„:")
        print(f"  - í‰ê°€ëœ ì¥ì†Œ ìˆ˜: {len(precisions)}")
        print(f"  - ìš°ìˆ˜(Precisionâ‰¥0.8): {sum(p>=0.8 for p in precisions)}")
        print(f"  - ì–‘í˜¸(0.6â‰¤P<0.8): {sum((p>=0.6) & (p<0.8) for p in precisions)}")
        print(f"  - ë³´í†µ(0.4â‰¤P<0.6): {sum((p>=0.4) & (p<0.6) for p in precisions)}")
        print(f"  - ê°œì„  í•„ìš”(P<0.4): {sum(p<0.4 for p in precisions)}")

        return {'precision': P, 'recall': R, 'f1_score': F1, 'ndcg': N}


    def haversine_distance(self, lat1, lon1, lat2, lon2):
        """
        ë‘ ì§€ì  ê°„ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚° (km)
        Haversine ê³µì‹ ì‚¬ìš©
        """
        lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])

        dlat = lat2 - lat1
        dlon = lon2 - lon1

        a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2
        c = 2 * np.arcsin(np.sqrt(a))

        # ì§€êµ¬ ë°˜ê²½ (km)
        r = 6371

        return c * r

    def filter_by_location(self, center_lat, center_lon, radius_km):
        """
        ìœ„ì¹˜ ë°˜ê²½ ë‚´ì˜ ì¥ì†Œë§Œ í•„í„°ë§

        Parameters:
        - center_lat: ì¤‘ì‹¬ ìœ„ë„
        - center_lon: ì¤‘ì‹¬ ê²½ë„
        - radius_km: ë°˜ê²½ (km)

        Returns:
        - í•„í„°ë§ëœ ì¥ì†Œ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """

        self.places_df['distances'] = self.places_df.apply(
            lambda row: self.haversine_distance(
                center_lat, center_lon,
                row['address_la'], row['address_lo']
            ),
            axis=1
        )

        within_radius = self.places_df['distances'] <= radius_km
        return self.places_df[within_radius].index.tolist()

    def recommend(self,
                  address=None,
                  suitables=None,
                  categorys=None,
                  center_location=None,
                  radius_km=51,
                  top_k=10):
        """
        ì—¬í–‰ì§€ ì¶”ì²œ

        Parameters:
        - suitables: êµ¬ì„±ì› ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['ê°€ì¡±', 'ì•„ì´'])
        - categorys: ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['ìì—°', 'ì‚¬ì§„'])
        - center_location: (ìœ„ë„, ê²½ë„) íŠœí”Œ
        - radius_km: ë°˜ê²½ (km)
        - top_k: ì¶”ì²œ ê°œìˆ˜

        Returns:
        - ì¶”ì²œ ì¥ì†Œ DataFrame
        """

        print("\n=== ì¶”ì²œ ì‹œì‘ ===")
        print(f"ğŸ“ ìœ„ì¹˜: {address}")
        print(f"ğŸ‘¥ êµ¬ì„±ì›: {suitables}")
        print(f"ğŸ¨ ì¹´í…Œê³ ë¦¬: {categorys}")
        print(f"ğŸ“ ì¤‘ì‹¬ ìœ„ì¹˜: ({center_location[0]:.4f}, {center_location[1]:.4f})")
        print(f"ğŸ“ ë°˜ê²½: {radius_km}km")

        # 1. í•„í„°ë§ ì‹œì‘
        candidate_indices = self.places_df.index.tolist()
        total_candidate_count = len(candidate_indices)
        distance_candidate_count = 0

        # recommend() ë§¨ ì•ì— ì¶”ê°€
        if center_location is not None:
           lat, lon = center_location
           # latì€ |ê°’|<=90, lonì€ |ê°’|<=180 ì´ ì •ìƒ
           if abs(lat) > 90 or abs(lon) > 180 or lat < 20 or lat > 50 or lon < 120 or lon > 140:
             # í•œêµ­ ì¢Œí‘œ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ (lon,lat)ë¡œ ë“¤ì–´ì™”ë‹¤ê³  ê°€ì •í•˜ê³  ìŠ¤ì™‘
             center_location = (lon, lat)

        # ìœ„ì¹˜ ë°˜ê²½ í•„í„°ë§
        if center_location and radius_km:
            location_indices = self.filter_by_location(
                center_location[0], center_location[1], radius_km
            )
            candidate_indices = list(set(candidate_indices) & set(location_indices))
            distance_candidate_count = len(candidate_indices)
            print(f"  â†’ ìœ„ì¹˜ ë°˜ê²½ í•„í„°ë§ í›„: {len(candidate_indices)}ê°œ")

        if len(candidate_indices) == 0:
            print("âš ï¸  ì¡°ê±´ì— ë§ëŠ” ì¥ì†Œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        # 2. ìŠ¤ì½”ì–´ ê³„ì‚°
        scores = np.zeros(len(self.places_df))
        print(f"  â†’ self.places_df : {self.places_df.columns}")

        # êµ¬ì„±ì› ë§¤ì¹­ ì ìˆ˜ ì¶”ê°€
        if suitables:
            for idx in candidate_indices:
                suitable = set(self.places_df.iloc[idx]['suitable_list'])
                suitable_match = len(set(suitables) & suitable) / len(suitables)
                scores[idx] += suitable_match * 0.5 # ê°€ì¤‘ì¹˜
        print(f"  â†’ êµ¬ì„±ì› ë§¤ì¹­ ì ìˆ˜ ì¶”ê°€ í›„ ì ìˆ˜ ë¶„í¬: {scores.mean():.4f} Â± {scores.std():.4f}")

        # ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ ì ìˆ˜ ì¶”ê°€
        if categorys:
            for idx in candidate_indices:
                place_categorys = set(self.places_df.iloc[idx]['category_list'])
                category_match = len(set(categorys) & place_categorys) / len(categorys)
                scores[idx] += category_match * 0.5 # ê°€ì¤‘ì¹˜
        print(f"  â†’ ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ ì ìˆ˜ ì¶”ê°€ í›„ ì ìˆ˜ ë¶„í¬: {scores.mean():.4f} Â± {scores.std():.4f}")

        # ê±°ë¦¬ ì ìˆ˜ ì¶”ê°€
        if center_location and radius_km:
            distance_match = distance_candidate_count / total_candidate_count
            for idx in candidate_indices:
                
                if self.places_df.iloc[idx]['distances'] <= 3:
                    scores[idx] += distance_match * 0.6
                elif self.places_df.iloc[idx]['distances'] <= 10:
                    scores[idx] += distance_match * 0.5
                elif self.places_df.iloc[idx]['distances'] <= 20:
                    scores[idx] += distance_match * 0.4
                elif self.places_df.iloc[idx]['distances'] <= 30:
                    scores[idx] += distance_match * 0.3
                elif self.places_df.iloc[idx]['distances'] <= 40:
                    scores[idx] += distance_match * 0.2
                else:
                    scores[idx] += distance_match * 0.1
        print(f"  â†’ ê±°ë¦¬ ë§¤ì¹­ ì ìˆ˜ ì¶”ê°€ í›„ ì ìˆ˜ ë¶„í¬: {scores.mean():.4f} Â± {scores.std():.4f}")

        # 3. í›„ë³´ ì¤‘ì—ì„œ Top-K ì„ íƒ
        candidate_scores = [(idx, scores[idx]) for idx in candidate_indices]
        candidate_scores.sort(key=lambda x: x[1], reverse=True)

        top_indices = [idx for idx, score in candidate_scores[:top_k]]

        # 4. ê²°ê³¼ ìƒì„±
        result_df = self.places_df.iloc[top_indices].copy()
        result_df['recommendation_score'] = [scores[idx] for idx in top_indices]

        # ì¤‘ì‹¬ ìœ„ì¹˜ê°€ ìˆìœ¼ë©´ ê±°ë¦¬ ê³„ì‚°
        if center_location:
            result_df['distance_km'] = result_df.apply(
                lambda row: self.haversine_distance(
                    center_location[0], center_location[1],
                    row['address_la'], row['address_lo']
                ),
                axis=1
            ).round(2)

        print(f"\nâœ… ì¶”ì²œ ì™„ë£Œ: {len(result_df)}ê°œ ì¥ì†Œ")

        return result_df

    def display_recommendations(self, recommendations):
        """ì¶”ì²œ ê²°ê³¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""

        if len(recommendations) == 0:
            print("\nì¶”ì²œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print("\n" + "="*80)
        print("ğŸ¯ ì¶”ì²œ ì—¬í–‰ì§€".center(80))
        print("="*80)

        for idx, (i, row) in enumerate(recommendations.iterrows(), 1):
            print(f"\n{idx}. {row['name']}")
            print(f"   ğŸ“ ìœ„ì¹˜: {row['address']}")
            print(f"   ğŸ·ï¸  ì¹´í…Œê³ ë¦¬: {row['category']}")
            if 'categorys' in row:
                print(f"   ğŸ¨ ì¹´í…Œê³ ë¦¬: {row['categorys']}")
            print(f"   ğŸ‘¥ ì í•©: {row['suitable']}")
            if 'rating' in row:
                print(f"   â­ í‰ì : {row['rating']}")
            print(f"   ğŸ“Š ì¶”ì²œ ì ìˆ˜: {row['recommendation_score']:.3f}")
            if 'distance_km' in row:
                print(f"   ğŸ“ ê±°ë¦¬: {row['distance_km']}km")

        print("\n" + "="*80)

    def save_model(self, model_path='recommendation_model.pkl'):
        """
        í›ˆë ¨ëœ ëª¨ë¸ ì €ì¥
        
        Parameters:
        - model_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
        """
        try:
            # Sparse matrixë¥¼ ê° ì»´í¬ë„ŒíŠ¸ë¡œ ì €ì¥ (ë©”ëª¨ë¦¬ ìµœì í™”)
            model_data = {
                'similarity_matrix': self.similarity_matrix,
                # feature_matrixëŠ” ì €ì¥í•˜ì§€ ì•ŠìŒ - ê° ì»´í¬ë„ŒíŠ¸ë§Œ ì €ì¥
                'tfidf_matrix': self.tfidf_matrix,
                'category_matrix': self.category_matrix,
                'suitable_matrix': self.suitable_matrix,
                'tfidf_vectorizer': self.tfidf_vectorizer,
                'mlb_category': self.mlb_category,
                'mlb_suitable': self.mlb_suitable,
                'scaler': self.scaler,
                'places_df': self.places_df,
                'address_similarity_matrix': self.address_similarity_matrix,
                'address_vectorizer': self.address_vectorizer
            }
            
            with open(model_path, 'wb') as f:
                pickle.dump(model_data, f)
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_size = os.path.getsize(model_path) / (1024 * 1024)  # MB
            
            print(f"âœ“ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")
            print(f"  - íŒŒì¼ í¬ê¸°: {file_size:.2f} MB")
            print(f"  - ìœ ì‚¬ë„ í–‰ë ¬: {self.similarity_matrix.shape if self.similarity_matrix is not None else 'None'}")
            print(f"  - ì§€ì—­ëª… ìœ ì‚¬ë„ í–‰ë ¬: {self.address_similarity_matrix.shape if self.address_similarity_matrix is not None else 'None'}")
            print(f"  - ì¥ì†Œ ìˆ˜: {len(self.places_df) if self.places_df is not None else 'None'}")
            return True
        except Exception as e:
            print(f"âœ— ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def load_model(self, model_path='CBF_recommendation_model.pkl'):
        """
        ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
        
        Parameters:
        - model_path: ë¶ˆëŸ¬ì˜¬ íŒŒì¼ ê²½ë¡œ
        """
        try:
            if not os.path.exists(model_path):
                print(f"âœ— ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")
                return False
            
            with open(model_path, 'rb') as f:
                model_data = pickle.load(f)
            
            self.similarity_matrix = model_data['similarity_matrix']
            self.tfidf_vectorizer = model_data['tfidf_vectorizer']
            self.mlb_category = model_data['mlb_category']
            self.mlb_suitable = model_data['mlb_suitable']
            self.scaler = model_data['scaler']
            self.places_df = model_data['places_df']
            
            # ê° ì»´í¬ë„ŒíŠ¸ ë¡œë“œ (ê¸°ì¡´ feature_matrix ì €ì¥ ë°©ì‹ê³¼ í˜¸í™˜ì„± ìœ ì§€)
            if 'tfidf_matrix' in model_data:
                # ìƒˆ ë²„ì „: ê° ì»´í¬ë„ŒíŠ¸ë¥¼ ë¡œë“œí•˜ê³  feature_matrix ì¬êµ¬ì„±
                self.tfidf_matrix = model_data['tfidf_matrix']
                self.category_matrix = model_data['category_matrix']
                self.suitable_matrix = model_data['suitable_matrix']
                self.feature_matrix = hstack([
                    self.tfidf_matrix,
                    self.category_matrix * 2,
                    self.suitable_matrix * 2
                ])
            elif 'feature_matrix' in model_data:
                # ê¸°ì¡´ ë²„ì „: feature_matrix ì§ì ‘ ë¡œë“œ
                self.feature_matrix = model_data['feature_matrix']
                print("  âš ï¸  ê¸°ì¡´ ëª¨ë¸ í˜•ì‹ì…ë‹ˆë‹¤. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ í´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                raise ValueError("ëª¨ë¸ íŒŒì¼ì— feature ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # ì§€ì—­ëª… ìœ ì‚¬ë„ í–‰ë ¬ ë¡œë“œ (ê¸°ì¡´ ëª¨ë¸ê³¼ í˜¸í™˜ì„± ìœ ì§€)
            if 'address_similarity_matrix' in model_data:
                self.address_similarity_matrix = model_data['address_similarity_matrix']
                self.address_vectorizer = model_data.get('address_vectorizer', TfidfVectorizer())
            else:
                # ê¸°ì¡´ ëª¨ë¸ì˜ ê²½ìš° ì§€ì—­ëª… ìœ ì‚¬ë„ í–‰ë ¬ ë‹¤ì‹œ ê³„ì‚°
                print("  - ì§€ì—­ëª… ìœ ì‚¬ë„ í–‰ë ¬ ì¬ê³„ì‚° ì¤‘...")
                self.address_vectorizer = TfidfVectorizer()
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_size = os.path.getsize(model_path) / (1024 * 1024)  # MB
            
            print(f"âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
            print(f"  - íŒŒì¼ í¬ê¸°: {file_size:.2f} MB")
            print(f"  - ìœ ì‚¬ë„ í–‰ë ¬: {self.similarity_matrix.shape if self.similarity_matrix is not None else 'None'}")
            print(f"  - ì§€ì—­ëª… ìœ ì‚¬ë„ í–‰ë ¬: {self.address_similarity_matrix.shape if self.address_similarity_matrix is not None else 'None'}")
            print(f"  - ì¥ì†Œ ìˆ˜: {len(self.places_df) if self.places_df is not None else 'None'}")
            return True
        except Exception as e:
            print(f"âœ— ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False